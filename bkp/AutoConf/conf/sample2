fs.checkpoint.period = 3600
fs.checkpoint.size = 67108864
fs.s3.block.size = 67108864
fs.s3.maxRetries = 4
fs.s3.sleepTimeSeconds = 10
fs.trash.interval = 0
hadoop.logfile.count = 10
hadoop.logfile.size = 10000000
hadoop.native.lib = true
io.bytes.per.checksum = 512
io.compression.codecs = org.apache.hadoop.io.compress.DefaultCodec = org.apache.hadoop.io.compress.GzipCodec = org.apache.hadoop.io.compress.BZip2Codec = org.apache.hadoop.io.compress.SnappyCodec
io.file.buffer.size = 4096
io.map.index.skip = 0
io.mapfile.bloom.error.rate = 0.005
io.mapfile.bloom.size = 1048576
io.seqfile.compress.blocksize = 1000000
io.seqfile.lazydecompress = true
io.seqfile.sorter.recordlimit = 1000000
io.skip.checksum.errors = false
io.sort.factor = 10
io.sort.mb = 100
io.sort.record.percent = 0.05
io.sort.spill.percent = 0.80
ipc.client.connect.max.retries = 10
ipc.client.connection.maxidletime = 10000
ipc.client.idlethreshold = 4000
ipc.client.kill.max = 10
ipc.client.tcpnodelay = false
ipc.server.listen.queue.size = 128
ipc.server.tcpnodelay = false
job.end.retry.attempts = 0
job.end.retry.interval = 30000
jobclient.output.filter = FAILED
keep.failed.task.files = false
local.cache.size = 10737418240
map.sort.class = org.apache.hadoop.util.QuickSort
mapred.child.java.opts = -Xmx200m
mapred.cluster.map.memory.mb = -1
mapred.cluster.max.map.memory.mb = -1
mapred.cluster.max.reduce.memory.mb = -1
mapred.cluster.reduce.memory.mb = -1
mapred.combine.recordsBeforeProgress = 10000
mapred.compress.map.output = false
mapred.healthChecker.interval = 60000
mapred.healthChecker.script.timeout = 600000
mapred.heartbeats.in.second = 100
mapred.inmem.merge.threshold = 1000
mapred.job.map.memory.mb = -1
mapred.job.reduce.input.buffer.percent = 0.0
mapred.job.reduce.memory.mb = -1
mapred.job.reuse.jvm.num.tasks = 1
mapred.job.shuffle.input.buffer.percent = 0.70
mapred.job.shuffle.merge.percent = 0.66
mapred.job.tracker = local
mapred.job.tracker.handler.count = 10
mapred.job.tracker.jobhistory.lru.cache.size = 5
mapred.job.tracker.persist.jobstatus.active = false
mapred.job.tracker.persist.jobstatus.hours = 0
mapred.job.tracker.retiredjobs.cache.size = 1000
mapred.jobtracker.blacklist.fault-bucket-width = 15
mapred.jobtracker.blacklist.fault-timeout-window = 180
mapred.jobtracker.completeuserjobs.maximum = 100
mapred.jobtracker.job.history.block.size = 3145728
mapred.jobtracker.maxtasks.per.job = -1
mapred.jobtracker.restart.recover = false
mapred.jobtracker.taskScheduler = org.apache.hadoop.mapred.JobQueueTaskScheduler
mapred.line.input.format.linespermap = 1
mapred.local.dir.minspacekill = 0
mapred.local.dir.minspacestart = 0
mapred.map.max.attempts = 4
mapred.map.output.compression.codec = org.apache.hadoop.io.compress.DefaultCodec
mapred.map.tasks = 2
mapred.map.tasks.speculative.execution = true
mapred.max.tracker.blacklists = 4
mapred.max.tracker.failures = 4
mapred.merge.recordsBeforeProgress = 10000
mapred.min.split.size = 0
mapred.output.compress = false
mapred.output.compression.codec = org.apache.hadoop.io.compress.DefaultCodec
mapred.output.compression.type = RECORD
mapred.queue.default.state = RUNNING
mapred.reduce.max.attempts = 4
mapred.reduce.parallel.copies = 5
mapred.reduce.slowstart.completed.maps = 0.05
mapred.reduce.tasks = 10
mapred.reduce.tasks.speculative.execution = true
mapred.skip.attempts.to.start.skipping = 2
mapred.skip.map.auto.incr.proc.count = true
mapred.skip.map.max.skip.records = 0
mapred.skip.reduce.auto.incr.proc.count = true
mapred.skip.reduce.max.skip.groups = 0
mapred.submit.replication = 10
mapred.task.cache.levels = 2
mapred.task.profile = false
mapred.task.profile.maps = 0-2
mapred.task.profile.reduces = 0-2
mapred.task.timeout = 600000
mapred.task.tracker.task-controller = org.apache.hadoop.mapred.DefaultTaskController
mapred.tasktracker.expiry.interval = 600000
mapred.tasktracker.indexcache.mb = 10
mapred.tasktracker.map.tasks.maximum = 2
mapred.tasktracker.reduce.tasks.maximum = 2
mapred.tasktracker.taskmemorymanager.monitoring-interval = 5000
mapred.tasktracker.tasks.sleeptime-before-sigkill = 5000
mapred.user.jobconf.limit = 5242880
mapred.userlog.limit.kb = 0
mapred.userlog.retain.hours = 24
mapreduce.job.complete.cancel.delegation.tokens = true
mapreduce.job.counters.limit = 120
mapreduce.job.split.metainfo.maxsize = 10000000
mapreduce.reduce.input.limit = -1
mapreduce.reduce.shuffle.connect.timeout = 180000
mapreduce.reduce.shuffle.maxfetchfailures = 10
mapreduce.reduce.shuffle.read.timeout = 180000
mapreduce.tasktracker.outofband.heartbeat = false
mapreduce.tasktracker.outofband.heartbeat.damper = 1000000
tasktracker.http.threads = 40
